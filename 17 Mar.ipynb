{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8238e8d2",
   "metadata": {},
   "source": [
    "### Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4495ba",
   "metadata": {},
   "source": [
    "Missing values are those values in a dataset that are not present or recorded for some or all of the data points. Handling missing values is essential because it can lead to biased results, incorrect statistical analysis, and inaccurate predictions. Some of the algorithms that are not affected by missing values include decision trees, Random Forests, and Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b390a5",
   "metadata": {},
   "source": [
    "### Q2: List down techniques used to handle missing data. Give an example of each with python code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635c6be8",
   "metadata": {},
   "source": [
    "Some techniques used to handle missing data are:\n",
    "\n",
    "* Mean/Median/Mode Imputation: Replace missing values with the mean, median, or mode of the available data.\n",
    "* Forward/Backward Fill: Replace missing values with the value that comes before or after it in the dataset.\n",
    "* Interpolation: Replace missing values with interpolated values based on the available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a700c750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B     C\n",
      "0  1.000000  5.000000   9.0\n",
      "1  2.000000  6.666667  10.0\n",
      "2  2.333333  7.000000  11.0\n",
      "3  4.000000  8.000000  10.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Mean/Median/Mode Imputation\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4], 'B': [5, np.nan, 7, 8], 'C': [9, 10, 11, np.nan]})\n",
    "\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "254897d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B     C\n",
      "0  1.000000  5.000000   9.0\n",
      "1  2.000000  6.666667  10.0\n",
      "2  2.333333  7.000000  11.0\n",
      "3  4.000000  8.000000  10.0\n"
     ]
    }
   ],
   "source": [
    "# Forward/Backward Fill\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34c6bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B     C\n",
      "0  1.000000  5.000000   9.0\n",
      "1  2.000000  6.666667  10.0\n",
      "2  2.333333  7.000000  11.0\n",
      "3  4.000000  8.000000  10.0\n"
     ]
    }
   ],
   "source": [
    "# Interpolation\n",
    "df.interpolate(method='linear', inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dc82a5",
   "metadata": {},
   "source": [
    "### Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f1fdf",
   "metadata": {},
   "source": [
    "Imbalanced data refers to a dataset where the distribution of classes is not equal. For example, in a binary classification problem, if one class has a much larger number of samples than the other class, then the data is said to be imbalanced. If imbalanced data is not handled, then the model can be biased towards the majority class and may perform poorly on the minority class. This can lead to incorrect predictions, incorrect model evaluation metrics, and lower model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9262de9b",
   "metadata": {},
   "source": [
    "### Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-sampling are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c955a3d0",
   "metadata": {},
   "source": [
    "Up-sampling is a technique of adding more samples to the minority class to balance the dataset. Down-sampling is a technique of removing some samples from the majority class to balance the dataset.\n",
    "\n",
    "For example, let's say we have a binary classification problem where the target variable has two classes, and the distribution is 90% for class 0 and 10% for class 1. This is an imbalanced dataset, and we can use up-sampling or down-sampling to balance it. If we choose to up-sample, we can duplicate the samples from the minority class to create more samples. If we choose to down-sample, we can remove some samples from the majority class to create a balanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33447d3c",
   "metadata": {},
   "source": [
    "### Q5: What is Data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e032ef6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Data augmentation is a technique used to increase the size and diversity of a training dataset by artificially generating new data points based on the existing ones. The goal is to improve the performance and generalization of machine learning models by providing more training examples.\n",
    "\n",
    "There are several ways to perform data augmentation, including:\n",
    "\n",
    "1. Rotation and flipping\n",
    "2. Scaling and cropping\n",
    "3. Adding noise and blur\n",
    "4. Changing brightness and contrast\n",
    "5. Randomly cutting out parts of images or texts\n",
    "6. Translation and distortion\n",
    "\n",
    "SMOTE, which stands for Synthetic Minority Over-sampling Technique, is a popular data augmentation technique used to address class imbalance in binary classification problems. It works by creating synthetic samples of the minority class by interpolating between existing samples.\n",
    "\n",
    "The SMOTE algorithm works as follows:\n",
    "\n",
    "1. Select a minority class sample as the starting point.\n",
    "2. Find the k-nearest neighbors of the starting point within the minority class.\n",
    "3. Randomly select one of the k-nearest neighbors and create a new sample by interpolating between the starting point and the selected neighbor.\n",
    "4. Repeat steps 1-3 until the desired number of synthetic samples has been generated.\n",
    "\n",
    "By creating new synthetic samples that are similar to the existing minority class samples, SMOTE helps to balance the distribution of classes and improve the performance of machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6ca7c",
   "metadata": {},
   "source": [
    "### Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7328743",
   "metadata": {},
   "source": [
    "Outliers are data points that are significantly different from other data points in a dataset. Handling outliers is important because they can skew the results of the analysis, affect the accuracy of machine learning models, and cause overfitting. Outliers can arise from errors or unusual data, and they should be investigated thoroughly before deciding whether to exclude them. Methods for handling outliers include removing them, transforming the data, or using robust statistical techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e27eab7",
   "metadata": {},
   "source": [
    "### Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4d95eb",
   "metadata": {},
   "source": [
    "There are several techniques that can be used to handle missing data in customer analysis, including:\n",
    "\n",
    "* Imputation: This involves filling in the missing values with estimated or predicted values based on the available data. This can be done using statistical techniques such as mean imputation or regression imputation.\n",
    "* Deletion: This involves removing the missing data points from the analysis. This can be done if the amount of missing data is small and the remaining data is still sufficient for analysis.\n",
    "* Prediction: This involves using machine learning algorithms to predict the missing values based on the available data. This can be done if there is a strong correlation between the missing values and other variables in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a38268f",
   "metadata": {},
   "source": [
    "### Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13e072b",
   "metadata": {},
   "source": [
    "To determine if the missing data is missing at random or if there is a pattern to the missing data, you can use techniques such as:\n",
    "\n",
    "* Visualizing the missing data: Plotting the missing data against other variables can help identify patterns.\n",
    "* Statistical tests: Conducting statistical tests can help determine if there is a relationship between the missing data and other variables in the dataset.\n",
    "* Machine learning techniques: Machine learning models can be used to predict the missing data based on the non-missing data, and the accuracy of these models can provide insight into the patterns of missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd25e513",
   "metadata": {},
   "source": [
    "### Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba67831",
   "metadata": {},
   "source": [
    "Some strategies for evaluating the performance of a machine learning model on an imbalanced dataset include:\n",
    "\n",
    "* Using appropriate evaluation metrics: Metrics such as precision, recall, and F1 score are better suited for imbalanced datasets than accuracy.\n",
    "* Resampling the dataset: Resampling techniques such as oversampling and undersampling can be used to balance the dataset and improve model performance.\n",
    "* Adjusting class weights: Most machine learning algorithms have a parameter that allows you to adjust the weight of each class. Increasing the weight of the minority class can help improve performance on imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef35c2e",
   "metadata": {},
   "source": [
    "### Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2637da",
   "metadata": {},
   "source": [
    "To balance the dataset and down-sample the majority class in the context of estimating customer satisfaction:\n",
    "\n",
    "* Random under-sampling: This method involves randomly removing some samples from the majority class until the number of samples in each class is more balanced. One downside of this approach is that it can result in a loss of information if important samples are removed.\n",
    "\n",
    "* Cluster centroid under-sampling: In this method, the majority class samples are first clustered, and then representative centroids are selected to keep in the dataset. This can help to maintain the information in the dataset while balancing the classes.\n",
    "\n",
    "* Tomek links under-sampling: This method involves identifying and removing samples from the majority class that are close to samples from the minority class. By increasing the margin between the classes, this method can help to improve the performance of the model on the minority class.\n",
    "\n",
    "* NearMiss under-sampling: Similar to Tomek links, NearMiss selects samples from the majority class that are closest to the minority class to increase the inter-class distance. This can help to reduce the overlap between the classes and improve the performance of the model on the minority class.\n",
    "\n",
    "* Combination of under-sampling and oversampling: This approach involves combining under-sampling of the majority class with oversampling of the minority class. For example, we can use Synthetic Minority Over-sampling Technique (SMOTE) to generate synthetic samples for the minority class, and then use random under-sampling to balance the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abe5285",
   "metadata": {},
   "source": [
    "### Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a057e0",
   "metadata": {},
   "source": [
    "There are several techniques to balance the dataset and up-sample the minority class:\n",
    "\n",
    "* Random oversampling: This technique involves randomly duplicating samples from the minority class to increase the number of samples in the dataset. This can be a simple and effective method, but it may result in overfitting if the same samples are used repeatedly.\n",
    "\n",
    "* Synthetic Minority Over-sampling Technique (SMOTE): This technique generates synthetic samples for the minority class by interpolating between the feature values of the minority class samples. This helps to increase the diversity of the samples in the minority class, reducing overfitting and improving the performance of the model.\n",
    "\n",
    "* Adaptive Synthetic (ADASYN): This method is similar to SMOTE, but instead of generating synthetic samples uniformly, it generates more samples near the borderline of the minority class. This can help to address the issue of overfitting and improve the generalization of the model.\n",
    "\n",
    "* Hybrid approaches: Hybrid approaches involve a combination of over-sampling and under-sampling techniques to balance the classes. For example, we can use SMOTE to generate synthetic samples for the minority class and then use Tomek Links or edited nearest neighbors to remove noisy samples from the majority class.\n",
    "\n",
    "* Cost-sensitive learning: Some machine learning algorithms allow the cost of misclassifying the minority class to be increased. By increasing the cost of misclassification, the model is encouraged to focus more on the minority class and can improve the performance on the rare event."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
